{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Entrega em Grupo - Plataforma 2025.1","text":""},{"location":"#apresentacao","title":"Apresenta\u00e7\u00e3o","text":"<p>Este site documenta a entrega em grupo de Gustavo Colombi Ribolla e Rafaela Aff\u00e9rri de Oliveira, realizada como parte do projeto final da disciplina de Plataformas 2025.1 no Insper.</p> <p>A proposta seguiu o mesmo molde da entrega individual, agora com o foco em colabora\u00e7\u00e3o, consolida\u00e7\u00e3o do conhecimento e integra\u00e7\u00e3o de pr\u00e1ticas modernas de deploy e escalabilidade com microsservi\u00e7os.</p>"},{"location":"#entregas-individuais","title":"Entregas Individuais","text":"<p>As implementa\u00e7\u00f5es individuais que serviram de base para a integra\u00e7\u00e3o deste trabalho em grupo foram documentadas separadamente e podem ser acessadas nos links abaixo:</p> <ul> <li>Entrega Individual de Rafaela Aff\u00e9rri de Oliveira</li> <li>Entrega Individual de Gustavo Colombi Ribolla</li> </ul>"},{"location":"#objetivo-do-projeto","title":"Objetivo do Projeto","text":"<p>A proposta da entrega consistiu em:</p> <ul> <li>Estruturar uma arquitetura em nuvem baseada em containers e microsservi\u00e7os</li> <li>Automatizar o deploy com CI/CD</li> <li>Utilizar EKS (Elastic Kubernetes Service) como plataforma de orquestra\u00e7\u00e3o</li> <li>Realizar testes de carga e an\u00e1lise de desempenho</li> <li>Aplicar boas pr\u00e1ticas de controle de custos em nuvem</li> <li>Documentar de forma clara e naveg\u00e1vel com MkDocs</li> </ul>"},{"location":"#organizacao-da-documentacao","title":"Organiza\u00e7\u00e3o da Documenta\u00e7\u00e3o","text":"<p>A documenta\u00e7\u00e3o est\u00e1 dividida em se\u00e7\u00f5es que cobrem cada aspecto da entrega:</p> <ul> <li>AWS \u2013 Descreve os servi\u00e7os utilizados, como IAM, EC2, S3 e EKS.</li> <li>EKS \u2013 Detalha a cria\u00e7\u00e3o e configura\u00e7\u00e3o do cluster Kubernetes na AWS.</li> <li>Testes de Carga \u2013 Apresenta os testes de desempenho realizados, ferramentas utilizadas e interpreta\u00e7\u00f5es.</li> <li>CI/CD \u2013 Explica a pipeline configurada no Jenkins, incluindo a automa\u00e7\u00e3o do deploy para o cluster.</li> <li>An\u00e1lise de Custos \u2013 Avalia o custo dos recursos utilizados e poss\u00edveis otimiza\u00e7\u00f5es.</li> <li>PaaS \u2013 Discute o conceito de Platform as a Service e alternativas \u00e0 arquitetura adotada.</li> </ul> <p>Autores: Gustavo Colombi Ribolla e Rafaela Aff\u00e9rri de Oliveira</p>"},{"location":"analise-de-custos/","title":"An\u00e1lise de Custos","text":""},{"location":"analise-de-custos/#introducao","title":"Introdu\u00e7\u00e3o","text":"<p>Para estimar os custos de execu\u00e7\u00e3o da nossa infraestrutura em produ\u00e7\u00e3o, utilizamos a ferramenta AWS Pricing Calculator. Embora nossa an\u00e1lise seja hipot\u00e9tica, ela reflete uma configura\u00e7\u00e3o realista baseada nos recursos utilizados ao longo do projeto.</p>"},{"location":"analise-de-custos/#estimativa-gerada","title":"Estimativa Gerada","text":"<p>Estimando que nossa aplica\u00e7\u00e3o teria um tamanho de baixo a m\u00e9dio porte, fizemos uma simula\u00e7\u00e3o que resultou em uma estimativa de custos:</p> <p></p> <p>A imagem acima mostra os valores simulados para os servi\u00e7os mencionados, totalizando um custo mensal compat\u00edvel com um ambiente acad\u00eamico de pequeno porte.</p>"},{"location":"analise-de-custos/#conclusao","title":"Conclus\u00e3o","text":"<p>A an\u00e1lise de custos hipot\u00e9tica nos ajudou a compreender como decis\u00f5es de arquitetura influenciam diretamente no or\u00e7amento do projeto. Al\u00e9m disso, refor\u00e7a a import\u00e2ncia de monitorar e otimizar continuamente os recursos em nuvem para evitar gastos desnecess\u00e1rios.</p> <p>Autores: Gustavo Colombi Ribolla e Rafaela Aff\u00e9rri de Oliveira</p>"},{"location":"aws/","title":"AWS","text":""},{"location":"aws/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>A AWS (Amazon Web Services) foi utilizada como a principal provedora de nuvem para hospedar a infraestrutura do projeto. A escolha se deu devido \u00e0 sua ampla ado\u00e7\u00e3o no mercado, escalabilidade e integra\u00e7\u00e3o com servi\u00e7os gerenciados como o EKS.</p>"},{"location":"aws/#servicos-utilizados","title":"Servi\u00e7os Utilizados","text":"<p>Durante o desenvolvimento e entrega do projeto, os seguintes servi\u00e7os da AWS foram empregados:</p> <ul> <li>EC2 (Elastic Compute Cloud): utilizado pontualmente para testes locais e suporte \u00e0 infraestrutura.</li> <li>IAM (Identity and Access Management): gerenciamento de permiss\u00f5es e acessos seguros aos recursos da nuvem.</li> <li>VPC (Virtual Private Cloud): rede privada configurada para isolar os recursos do projeto.</li> <li>EKS (Elastic Kubernetes Service): servi\u00e7o gerenciado de Kubernetes utilizado para orquestra\u00e7\u00e3o dos microsservi\u00e7os da aplica\u00e7\u00e3o.</li> </ul> <p></p>"},{"location":"aws/#api-em-producao","title":"API em produ\u00e7\u00e3o","text":"<p>A aplica\u00e7\u00e3o foi exposta publicamente por meio de um Load Balancer gerado automaticamente pelo servi\u00e7o EKS.</p> <p>O endpoint da API em execu\u00e7\u00e3o \u00e9:</p> <pre><code>http://abcad5ad7b3a448dea1af26b7b679e7f-1432887122.us-east-2.elb.amazonaws.com:8080\n</code></pre> <p>Esse endpoint retorna informa\u00e7\u00f5es sobre o microsservi\u00e7o e valida a disponibilidade do sistema implantado na nuvem.</p>"},{"location":"aws/#conclusao","title":"Conclus\u00e3o","text":"<p>A AWS proporcionou uma base robusta e segura para o deploy da aplica\u00e7\u00e3o, com ferramentas que permitiram desde a cria\u00e7\u00e3o do cluster Kubernetes at\u00e9 a exposi\u00e7\u00e3o da aplica\u00e7\u00e3o via Load Balancer com alta disponibilidade.</p> <p>Autores: Gustavo Colombi Ribolla e Rafaela Aff\u00e9rri de Oliveira</p>"},{"location":"ci-cd/","title":"CI/CD","text":"<p>A entrega cont\u00ednua da aplica\u00e7\u00e3o foi automatizada utilizando o Jenkins, uma das ferramentas de integra\u00e7\u00e3o cont\u00ednua mais consolidadas do mercado.</p>"},{"location":"ci-cd/#jenkins","title":"Jenkins","text":"<p>O Jenkins \u00e9 uma plataforma de automa\u00e7\u00e3o open-source amplamente utilizada para CI/CD. Ele permite a orquestra\u00e7\u00e3o de pipelines que automatizam desde os testes at\u00e9 o deploy em produ\u00e7\u00e3o.</p> <p></p>"},{"location":"ci-cd/#jenkinsfile-interfaces","title":"Jenkinsfile \u2013 Interfaces","text":"<p>As interfaces (como <code>product</code>, <code>order</code>, <code>account</code>) utilizam um Jenkinsfile simples para build Maven:</p> <pre><code>pipeline {\n    agent any\n\n    stages {\n        stage('Build') {\n            steps {\n                sh 'mvn -B -DskipTests clean install'\n            }\n        }\n    }\n}\n</code></pre> <p>Este pipeline compila o c\u00f3digo e garante que as depend\u00eancias estejam corretas, mas n\u00e3o realiza deploy de imagens.</p>"},{"location":"ci-cd/#jenkinsfile-services","title":"Jenkinsfile \u2013 Services","text":"<p>Para os services (como <code>order-service</code>, <code>product-service</code>, etc.), o Jenkinsfile realiza tamb\u00e9m o build da imagem Docker e seu push para o Docker Hub:</p> <pre><code>pipeline {\n    agent any\n    environment {\n        SERVICE = 'order-service'\n        NAME = \"rafaelaafferri/${env.SERVICE}\"\n    }\n    stages {\n        stage('Dependecies') {\n            steps {\n                build job: 'order', wait: true\n                build job: 'product', wait: true\n            }\n        }\n        stage('Build') { \n            steps {\n                sh 'mvn -B -DskipTests clean package'\n            }\n        }      \n        stage('Build &amp; Push Image') {\n            steps {\n                withCredentials([usernamePassword(credentialsId: 'dockerhub-credential', usernameVariable: 'USERNAME', passwordVariable: 'TOKEN')]) {\n                    sh \"docker login -u $USERNAME -p $TOKEN\"\n                    sh \"docker buildx create --use --platform=linux/arm64,linux/amd64 --node multi-platform-builder-${env.SERVICE} --name multi-platform-builder-${env.SERVICE}\"\n                    sh \"docker buildx build --platform=linux/arm64,linux/amd64 --push --tag ${env.NAME}:latest --tag ${env.NAME}:${env.BUILD_ID} -f Dockerfile .\"\n                    sh \"docker buildx rm --force multi-platform-builder-${env.SERVICE}\"\n                }\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"ci-cd/#pipeline-de-deploy","title":"Pipeline de Deploy","text":"<p>Na nossa solu\u00e7\u00e3o, o Jenkins foi configurado para realizar o <code>kubectl apply</code> dos manifests diretamente no cluster gerenciado pela AWS atrav\u00e9s do EKS.</p>"},{"location":"ci-cd/#etapas-principais-do-pipeline","title":"Etapas principais do pipeline:","text":"<ol> <li>Checkout do reposit\u00f3rio com os manifests e a aplica\u00e7\u00e3o.</li> <li>Build da imagem da aplica\u00e7\u00e3o e push para o reposit\u00f3rio.</li> <li>Deploy automatizado via <code>kubectl apply -f</code> dos arquivos YAML na AWS.</li> </ol> <p>Esse processo garante que qualquer mudan\u00e7a realizada no c\u00f3digo seja rapidamente propagada para o ambiente em nuvem, assegurando confiabilidade e agilidade no ciclo de vida da aplica\u00e7\u00e3o.</p> <p>Autores: Gustavo Colombi Ribolla e Rafaela Aff\u00e9rri de Oliveira</p>"},{"location":"eks/","title":"EKS (Elastic Kubernetes Service)","text":""},{"location":"eks/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>Utilizamos o Amazon EKS como nossa plataforma de orquestra\u00e7\u00e3o de containers. Esse servi\u00e7o permite executar aplica\u00e7\u00f5es em cont\u00eaineres usando Kubernetes gerenciado, o que facilita o deploy e a escalabilidade de microsservi\u00e7os.</p>"},{"location":"eks/#deploy-via-jenkins","title":"Deploy via Jenkins","text":"<p>O processo de deploy foi automatizado atrav\u00e9s do Jenkins, que aplicava os manifests (<code>.yaml</code>) de cada microsservi\u00e7o diretamente no cluster EKS. Cada servi\u00e7o possu\u00eda seus pr\u00f3prios arquivos de configura\u00e7\u00e3o, garantindo modularidade e organiza\u00e7\u00e3o.</p> <p></p>"},{"location":"eks/#gateway-e-load-balancer","title":"Gateway e Load Balancer","text":"<p>O gateway da aplica\u00e7\u00e3o foi exposto ao p\u00fablico por meio de um Load Balancer gerado automaticamente pelo EKS. Esse Load Balancer atua como ponto de entrada para as requisi\u00e7\u00f5es externas, encaminhando-as corretamente para os servi\u00e7os no cluster.</p> <p>Autores: Gustavo Colombi Ribolla e Rafaela Aff\u00e9rri de Oliveira</p>"},{"location":"paas/","title":"Uso de PaaS no Projeto","text":""},{"location":"paas/#o-que-e-paas","title":"O que \u00e9 PaaS?","text":"<p>PaaS (Plataforma como Servi\u00e7o) \u00e9 um modelo de computa\u00e7\u00e3o em nuvem que fornece um ambiente gerenciado para desenvolver, testar e executar aplica\u00e7\u00f5es, abstraindo a infraestrutura subjacente. Com PaaS, a equipe de desenvolvimento pode focar no c\u00f3digo e na l\u00f3gica da aplica\u00e7\u00e3o, enquanto a plataforma cuida de aspectos como provisionamento de recursos, escalabilidade e atualiza\u00e7\u00e3o de ambiente.</p> <p></p>"},{"location":"paas/#onde-utilizamos-paas-no-projeto","title":"Onde Utilizamos PaaS no Projeto","text":""},{"location":"paas/#1-amazon-eks-elastic-kubernetes-service","title":"1. Amazon EKS (Elastic Kubernetes Service)","text":"<p>Utilizamos o Amazon EKS para orquestrar os containers dos nossos microservi\u00e7os. Ele \u00e9 um exemplo de PaaS voltado para orquestra\u00e7\u00e3o de cont\u00eaineres, pois:</p> <ul> <li>A AWS gerencia automaticamente os n\u00f3s de controle do Kubernetes.</li> <li>Oferece integra\u00e7\u00e3o facilitada com servi\u00e7os como IAM, VPC, Load Balancer e auto scaling.</li> <li>Permite executar, escalar e monitorar os servi\u00e7os com m\u00ednima configura\u00e7\u00e3o de infraestrutura.</li> </ul>"},{"location":"paas/#2-jenkins-pipeline-cicd-como-servico","title":"2. Jenkins (Pipeline CI/CD como servi\u00e7o)","text":"<p>O Jenkins foi utilizado para automa\u00e7\u00e3o do processo de integra\u00e7\u00e3o cont\u00ednua e entrega cont\u00ednua (CI/CD). Ele pode ser considerado uma ferramenta PaaS self-managed ou hospedada, dependendo do ambiente:</p> <ul> <li>Automatiza o build, testes e deploy da aplica\u00e7\u00e3o em cada push de c\u00f3digo.</li> <li>Pode ser integrado ao EKS para realizar deploy direto nos pods.</li> <li>Reduz o esfor\u00e7o manual de atualiza\u00e7\u00f5es e versionamento.</li> </ul>"},{"location":"paas/#3-postgresql-com-docker","title":"3. PostgreSQL com Docker","text":"<p>Mesmo utilizando PostgreSQL em containers, ele pode ser considerado parte de uma arquitetura tipo PaaS:</p> <ul> <li>A persist\u00eancia e configura\u00e7\u00e3o do banco s\u00e3o automatizadas via Docker e Kubernetes.</li> <li>Em ambientes reais, seria comum utilizar um servi\u00e7o gerenciado como RDS (AWS) ou ElephantSQL.</li> </ul>"},{"location":"paas/#beneficios-do-uso-de-paas","title":"Benef\u00edcios do Uso de PaaS","text":"<ul> <li>Abstra\u00e7\u00e3o da infraestrutura complexa (especialmente via EKS).</li> <li>Automa\u00e7\u00e3o de processos repetitivos com Jenkins, garantindo entregas cont\u00ednuas.</li> <li>Escalabilidade e monitoramento nativos no EKS.</li> <li>Foco no desenvolvimento e n\u00e3o na infraestrutura.</li> </ul>"},{"location":"testes-de-carga/","title":"Teste de Carga com HPA","text":"<p>Neste experimento, realizamos um teste de carga na aplica\u00e7\u00e3o <code>gateway</code> do sistema, com o objetivo de observar o comportamento do HPA (Horizontal Pod Autoscaler) em um cluster Kubernetes.</p>"},{"location":"testes-de-carga/#objetivo","title":"Objetivo","text":"<p>Avaliar a escalabilidade autom\u00e1tica de pods do microservi\u00e7o <code>gateway</code> em resposta ao aumento de uso de CPU provocado por m\u00faltiplas requisi\u00e7\u00f5es simult\u00e2neas.</p>"},{"location":"testes-de-carga/#configuracao-do-dashboard","title":"Configura\u00e7\u00e3o do Dashboard","text":"<p>Para visualiza\u00e7\u00e3o gr\u00e1fica dos recursos do cluster e do comportamento do HPA, utilizamos o Kubernetes Dashboard. A instala\u00e7\u00e3o foi feita com os comandos:</p> <pre><code>kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.7.0/aio/deploy/recommended.yaml\nkubectl proxy\n</code></pre> <p>O acesso foi feito via browser em:</p> <pre><code>http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/\n</code></pre>"},{"location":"testes-de-carga/#comandos-utilizados","title":"Comandos Utilizados","text":""},{"location":"testes-de-carga/#criacao-do-hpa","title":"Cria\u00e7\u00e3o do HPA","text":"<pre><code>kubectl autoscale deployment gateway --cpu-percent=50 --min=1 --max=10\n</code></pre> <p>Esse comando cria um autoscaler horizontal baseado em uso de CPU, com um limite m\u00ednimo de 1 pod e m\u00e1ximo de 10 pods.</p>"},{"location":"testes-de-carga/#execucao-do-teste-de-carga","title":"Execu\u00e7\u00e3o do teste de carga","text":"<pre><code>kubectl run -i --tty load-generator --rm --image=busybox:1.28 --restart=Never -- /bin/sh -c \"while sleep 0.01; do wget -qO- http://gateway:8080/info; done\"\n</code></pre> <p>Esse comando cria um pod tempor\u00e1rio que envia requisi\u00e7\u00f5es constantes para o endpoint <code>/info</code> do microservi\u00e7o <code>gateway</code>.</p>"},{"location":"testes-de-carga/#resultado","title":"Resultado","text":"<p>Durante o teste, o n\u00famero de r\u00e9plicas do <code>gateway</code> aumentou progressivamente conforme a CPU m\u00e9dia ultrapassava o limite de 50%. Isso confirma que o HPA est\u00e1 corretamente configurado e reagindo \u00e0s condi\u00e7\u00f5es de carga.</p> <p>Abaixo est\u00e1 um print do dashboard do Kubernetes mostrando o estado do HPA durante o teste:</p> <p></p>"},{"location":"testes-de-carga/#ferramentas-utilizadas","title":"Ferramentas Utilizadas","text":"<ul> <li>Kubernetes Dashboard: https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/</li> <li>Documenta\u00e7\u00e3o HPA: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/</li> </ul>"},{"location":"testes-de-carga/#conclusao","title":"Conclus\u00e3o","text":"<p>O teste demonstrou que o autoscaling horizontal funciona conforme o esperado e responde rapidamente a picos de carga. O Kubernetes Dashboard foi essencial para visualizar em tempo real o comportamento dos pods e do HPA.</p>"}]}